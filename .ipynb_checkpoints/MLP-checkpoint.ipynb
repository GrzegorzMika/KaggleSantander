{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import scipy.stats as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos as talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_dir = '/home/grzegorz/Kaggle/Santander', split = 0.2):\n",
    "    train_data = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "    test_data = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "    y_train = train_data['target']\n",
    "    x_train = train_data.drop(columns = ['ID_code', 'target'])\n",
    "    scaler = QuantileTransformer()\n",
    "    scaler.fit(x_train)\n",
    "    test_data.iloc[:,1:201] = scaler.transform(test_data.iloc[:,1:201])\n",
    "    train_data = scaler.transform(x_train)\n",
    "    train_x_data = x_train\n",
    "    train_y_data = y_train\n",
    "    x_train, x_val, y_train, y_val = train_test_split(train_x_data, train_y_data, test_size = split)\n",
    "    return np.array(x_train), np.array(x_val), test_data, np.array(y_train), np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.7 s, sys: 1.08 s, total: 20.7 s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%time x_train, x_val, x_test, y_train, y_val = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'first_neuron_dim': [512, 256, 128, 64, 32, 16],\n",
    "    'first_neuron_act': ['relu'],\n",
    "    'first_dropout': [0, 0.2, 0.5, 0.8],\n",
    "    'second_neuron_dim': [512, 256, 128, 64, 32, 16],\n",
    "    'second_neuron_act': ['relu', 'linear'],\n",
    "    'second_dropout': [0, 0.2, 0.5, 0.8],\n",
    "    'third_neuron_dim': [512, 256, 128, 64, 32, 16],\n",
    "    'third_neuron_act': ['relu', 'linear'],\n",
    "    'third_dropout': [0, 0.2, 0.5, 0.8],\n",
    "    'l1_regularization_1':[1e-4, 1e-3, 1e-2, 1e-1, 0, 1, 10],\n",
    "    'l1_regularization_2':[1e-4, 1e-3, 1e-2, 1e-1, 0, 1, 10],\n",
    "    'l1_regularization_3':[1e-4, 1e-3, 1e-2, 1e-1, 0, 1, 10],\n",
    "    'optimizer': ['adam', 'nadam'],\n",
    "    'batch_size': [32768, 2048, 128],\n",
    "    'epochs': [50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [keras.callbacks.EarlyStopping(monitor = 'val_acc', patience = 6),\n",
    "                  keras.callbacks.ReduceLROnPlateau(patience = 4),\n",
    "                  keras.callbacks.TensorBoard()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_model(x_train, y_train, x_val, y_val, params):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(params['first_neuron_dim'], activation = params['first_neuron_act'], \n",
    "        kernel_regularizer = keras.regularizers.l1(params['l1_regularization_1']), \n",
    "        kernel_initializer = keras.initializers.glorot_normal(), input_shape = (200,)))\n",
    "    model.add(keras.layers.Dropout(params['first_dropout']))\n",
    "    model.add(keras.layers.Dense(params['second_neuron_dim'], activation = params['second_neuron_act'],\n",
    "             kernel_regularizer = keras.regularizers.l1(params['l1_regularization_2']),\n",
    "             kernel_initializer = keras.initializers.glorot_normal())) \n",
    "    model.add(keras.layers.Dropout(params['second_dropout']))\n",
    "    model.add(keras.layers.Dense(params['third_neuron_dim'], activation = params['third_neuron_act'],\n",
    "             kernel_regularizer = keras.regularizers.l1(params['l1_regularization_3']),\n",
    "             kernel_initializer = keras.initializers.glorot_normal()))\n",
    "    model.add(keras.layers.Dropout(params['third_dropout']))\n",
    "    model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer = params['optimizer'], loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "    history = model.fit(x_train, y_train, batch_size = params['batch_size'], epochs = params['epochs'], \n",
    "                       callbacks = callbacks_list, validation_data = [x_val, y_val])\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_neuron_dim': 256, 'first_neuron_act': 'relu', 'first_dropout': 0.2, 'second_neuron_dim': 16, 'second_neuron_act': 'relu', 'second_dropout': 0, 'third_neuron_dim': 512, 'third_neuron_act': 'relu', 'third_dropout': 0.8, 'l1_regularization_1': 1, 'l1_regularization_2': 10, 'l1_regularization_3': 1, 'optimizer': 'adam', 'batch_size': 128, 'epochs': 50}\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/50\n",
      "160000/160000 [==============================] - 7s 45us/step - loss: 239.2556 - acc: 0.8932 - val_loss: 12.9366 - val_acc: 0.8982\n",
      "Epoch 2/50\n",
      "160000/160000 [==============================] - 9s 55us/step - loss: 12.9103 - acc: 0.8999 - val_loss: 12.8162 - val_acc: 0.8982\n",
      "Epoch 3/50\n",
      "160000/160000 [==============================] - 8s 53us/step - loss: 12.9094 - acc: 0.8999 - val_loss: 13.0767 - val_acc: 0.8982\n",
      "Epoch 4/50\n",
      "160000/160000 [==============================] - 8s 52us/step - loss: 12.9078 - acc: 0.8999 - val_loss: 12.8653 - val_acc: 0.8982\n",
      "Epoch 5/50\n",
      "160000/160000 [==============================] - 10s 62us/step - loss: 12.9073 - acc: 0.8999 - val_loss: 12.8108 - val_acc: 0.8982\n",
      "Epoch 6/50\n",
      "160000/160000 [==============================] - 10s 60us/step - loss: 12.9062 - acc: 0.8999 - val_loss: 12.9077 - val_acc: 0.8982\n",
      "Epoch 7/50\n",
      "160000/160000 [==============================] - 8s 52us/step - loss: 12.9072 - acc: 0.8999 - val_loss: 12.8523 - val_acc: 0.8982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [01:01<04:04, 61.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_neuron_dim': 128, 'first_neuron_act': 'relu', 'first_dropout': 0.8, 'second_neuron_dim': 32, 'second_neuron_act': 'relu', 'second_dropout': 0.5, 'third_neuron_dim': 128, 'third_neuron_act': 'linear', 'third_dropout': 0, 'l1_regularization_1': 0.01, 'l1_regularization_2': 0.1, 'l1_regularization_3': 0, 'optimizer': 'adam', 'batch_size': 128, 'epochs': 50}\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/50\n",
      "160000/160000 [==============================] - 9s 54us/step - loss: 4.0408 - acc: 0.8979 - val_loss: 0.3983 - val_acc: 0.8982\n",
      "Epoch 2/50\n",
      "160000/160000 [==============================] - 8s 53us/step - loss: 0.3946 - acc: 0.8999 - val_loss: 0.3981 - val_acc: 0.8982\n",
      "Epoch 3/50\n",
      "160000/160000 [==============================] - 9s 55us/step - loss: 0.3951 - acc: 0.8999 - val_loss: 0.3999 - val_acc: 0.8982\n",
      "Epoch 4/50\n",
      "160000/160000 [==============================] - 10s 60us/step - loss: 0.3952 - acc: 0.8999 - val_loss: 0.3989 - val_acc: 0.8982\n",
      "Epoch 5/50\n",
      "160000/160000 [==============================] - 9s 56us/step - loss: 0.3954 - acc: 0.8999 - val_loss: 0.3989 - val_acc: 0.8982\n",
      "Epoch 6/50\n",
      "160000/160000 [==============================] - 9s 58us/step - loss: 0.3954 - acc: 0.8999 - val_loss: 0.3992 - val_acc: 0.8982\n",
      "Epoch 7/50\n",
      "160000/160000 [==============================] - 7s 46us/step - loss: 0.3339 - acc: 0.8999 - val_loss: 0.3372 - val_acc: 0.8982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [02:03<03:04, 61.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_neuron_dim': 512, 'first_neuron_act': 'relu', 'first_dropout': 0.2, 'second_neuron_dim': 16, 'second_neuron_act': 'relu', 'second_dropout': 0, 'third_neuron_dim': 64, 'third_neuron_act': 'linear', 'third_dropout': 0.5, 'l1_regularization_1': 10, 'l1_regularization_2': 0.1, 'l1_regularization_3': 0.0001, 'optimizer': 'adam', 'batch_size': 128, 'epochs': 50}\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/50\n",
      "160000/160000 [==============================] - 8s 48us/step - loss: 1336.8054 - acc: 0.8978 - val_loss: 127.1649 - val_acc: 0.8982\n",
      "Epoch 2/50\n",
      "160000/160000 [==============================] - 9s 53us/step - loss: 127.1368 - acc: 0.8999 - val_loss: 126.2423 - val_acc: 0.8982\n",
      "Epoch 3/50\n",
      "160000/160000 [==============================] - 9s 53us/step - loss: 127.1030 - acc: 0.8999 - val_loss: 127.4635 - val_acc: 0.8982\n",
      "Epoch 4/50\n",
      "160000/160000 [==============================] - 9s 58us/step - loss: 127.0919 - acc: 0.8999 - val_loss: 126.7235 - val_acc: 0.8982\n",
      "Epoch 5/50\n",
      "160000/160000 [==============================] - 9s 55us/step - loss: 127.0865 - acc: 0.8999 - val_loss: 126.0003 - val_acc: 0.8982\n",
      "Epoch 6/50\n",
      "160000/160000 [==============================] - 9s 54us/step - loss: 127.0847 - acc: 0.8999 - val_loss: 126.8567 - val_acc: 0.8982\n",
      "Epoch 7/50\n",
      "160000/160000 [==============================] - 9s 55us/step - loss: 127.0812 - acc: 0.8999 - val_loss: 126.8803 - val_acc: 0.8982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [03:03<02:02, 61.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_neuron_dim': 32, 'first_neuron_act': 'relu', 'first_dropout': 0.5, 'second_neuron_dim': 16, 'second_neuron_act': 'linear', 'second_dropout': 0.2, 'third_neuron_dim': 32, 'third_neuron_act': 'relu', 'third_dropout': 0.8, 'l1_regularization_1': 0, 'l1_regularization_2': 0.1, 'l1_regularization_3': 1, 'optimizer': 'adam', 'batch_size': 128, 'epochs': 50}\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/50\n",
      "160000/160000 [==============================] - 7s 45us/step - loss: 10.1669 - acc: 0.8898 - val_loss: 0.3877 - val_acc: 0.8982\n",
      "Epoch 2/50\n",
      "160000/160000 [==============================] - 8s 48us/step - loss: 0.4036 - acc: 0.8999 - val_loss: 0.3915 - val_acc: 0.8982\n",
      "Epoch 3/50\n",
      "160000/160000 [==============================] - 8s 52us/step - loss: 0.3940 - acc: 0.8999 - val_loss: 0.3898 - val_acc: 0.8982\n",
      "Epoch 4/50\n",
      "160000/160000 [==============================] - 9s 56us/step - loss: 0.3893 - acc: 0.8999 - val_loss: 0.3905 - val_acc: 0.8982\n",
      "Epoch 5/50\n",
      "160000/160000 [==============================] - 8s 51us/step - loss: 0.3876 - acc: 0.8999 - val_loss: 0.3907 - val_acc: 0.8982\n",
      "Epoch 6/50\n",
      "160000/160000 [==============================] - 10s 62us/step - loss: 0.3329 - acc: 0.8999 - val_loss: 0.3356 - val_acc: 0.8982\n",
      "Epoch 7/50\n",
      "160000/160000 [==============================] - 9s 56us/step - loss: 0.3323 - acc: 0.8999 - val_loss: 0.3361 - val_acc: 0.8982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [04:03<01:00, 60.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_neuron_dim': 16, 'first_neuron_act': 'relu', 'first_dropout': 0.5, 'second_neuron_dim': 512, 'second_neuron_act': 'relu', 'second_dropout': 0.8, 'third_neuron_dim': 128, 'third_neuron_act': 'relu', 'third_dropout': 0, 'l1_regularization_1': 0.0001, 'l1_regularization_2': 0.1, 'l1_regularization_3': 0.001, 'optimizer': 'adam', 'batch_size': 1024, 'epochs': 50}\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/50\n",
      "160000/160000 [==============================] - 1s 6us/step - loss: 12.2315 - acc: 0.8949 - val_loss: 0.8773 - val_acc: 0.8982\n",
      "Epoch 2/50\n",
      "160000/160000 [==============================] - 1s 5us/step - loss: 0.6330 - acc: 0.8999 - val_loss: 0.5113 - val_acc: 0.8982\n",
      "Epoch 3/50\n",
      "160000/160000 [==============================] - 1s 6us/step - loss: 0.4725 - acc: 0.8999 - val_loss: 0.4550 - val_acc: 0.8982\n",
      "Epoch 4/50\n",
      "160000/160000 [==============================] - 1s 5us/step - loss: 0.4450 - acc: 0.8999 - val_loss: 0.4447 - val_acc: 0.8982\n",
      "Epoch 5/50\n",
      "160000/160000 [==============================] - 1s 6us/step - loss: 0.4387 - acc: 0.8999 - val_loss: 0.4403 - val_acc: 0.8982\n",
      "Epoch 6/50\n",
      "160000/160000 [==============================] - 1s 6us/step - loss: 0.4357 - acc: 0.8999 - val_loss: 0.4389 - val_acc: 0.8982\n",
      "Epoch 7/50\n",
      "160000/160000 [==============================] - 1s 6us/step - loss: 0.4330 - acc: 0.8999 - val_loss: 0.4364 - val_acc: 0.8982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [04:10<00:00, 44.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "scan = talos.Scan(x_train, y_train, x_val = x_val, y_val = y_val, params = params, model = MLP_model,\n",
    "                 print_params = True, dataset_name = 'Results/Santander', experiment_no = '2',\n",
    "                 grid_downsample = 0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>lr</th>\n",
       "      <th>first_neuron_dim</th>\n",
       "      <th>first_neuron_act</th>\n",
       "      <th>first_dropout</th>\n",
       "      <th>second_neuron_dim</th>\n",
       "      <th>...</th>\n",
       "      <th>second_dropout</th>\n",
       "      <th>third_neuron_dim</th>\n",
       "      <th>third_neuron_act</th>\n",
       "      <th>third_dropout</th>\n",
       "      <th>l1_regularization_1</th>\n",
       "      <th>l1_regularization_2</th>\n",
       "      <th>l1_regularization_3</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>12.810829</td>\n",
       "      <td>0.89815</td>\n",
       "      <td>12.906195</td>\n",
       "      <td>0.89985</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>adam</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.337174</td>\n",
       "      <td>0.89815</td>\n",
       "      <td>0.333932</td>\n",
       "      <td>0.89985</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.8</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>128</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>adam</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>126.000252</td>\n",
       "      <td>0.89815</td>\n",
       "      <td>127.081189</td>\n",
       "      <td>0.89985</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>512</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.335585</td>\n",
       "      <td>0.89815</td>\n",
       "      <td>0.332300</td>\n",
       "      <td>0.89985</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>adam</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.436377</td>\n",
       "      <td>0.89815</td>\n",
       "      <td>0.432969</td>\n",
       "      <td>0.89985</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>adam</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   round_epochs    val_loss  val_acc        loss      acc      lr  \\\n",
       "0             7   12.810829  0.89815   12.906195  0.89985  0.0010   \n",
       "1             7    0.337174  0.89815    0.333932  0.89985  0.0001   \n",
       "2             7  126.000252  0.89815  127.081189  0.89985  0.0010   \n",
       "3             7    0.335585  0.89815    0.332300  0.89985  0.0001   \n",
       "4             7    0.436377  0.89815    0.432969  0.89985  0.0010   \n",
       "\n",
       "   first_neuron_dim first_neuron_act  first_dropout  second_neuron_dim  ...  \\\n",
       "0               256             relu            0.2                 16  ...   \n",
       "1               128             relu            0.8                 32  ...   \n",
       "2               512             relu            0.2                 16  ...   \n",
       "3                32             relu            0.5                 16  ...   \n",
       "4                16             relu            0.5                512  ...   \n",
       "\n",
       "  second_dropout  third_neuron_dim  third_neuron_act third_dropout  \\\n",
       "0            0.0               512              relu           0.8   \n",
       "1            0.5               128            linear           0.0   \n",
       "2            0.0                64            linear           0.5   \n",
       "3            0.2                32              relu           0.8   \n",
       "4            0.8               128              relu           0.0   \n",
       "\n",
       "   l1_regularization_1  l1_regularization_2  l1_regularization_3  optimizer  \\\n",
       "0               1.0000                 10.0               1.0000       adam   \n",
       "1               0.0100                  0.1               0.0000       adam   \n",
       "2              10.0000                  0.1               0.0001       adam   \n",
       "3               0.0000                  0.1               1.0000       adam   \n",
       "4               0.0001                  0.1               0.0010       adam   \n",
       "\n",
       "  batch_size  epochs  \n",
       "0        128      50  \n",
       "1        128      50  \n",
       "2        128      50  \n",
       "3        128      50  \n",
       "4       1024      50  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan.data.sort_values('val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/10\n",
      "160000/160000 [==============================] - 8s 53us/step - loss: 1.4912 - acc: 0.8997 - val_loss: 0.7656 - val_acc: 0.8982\n",
      "Epoch 2/10\n",
      "160000/160000 [==============================] - 10s 61us/step - loss: 0.7565 - acc: 0.9033 - val_loss: 0.7426 - val_acc: 0.9053\n",
      "Epoch 3/10\n",
      "160000/160000 [==============================] - 8s 51us/step - loss: 0.7396 - acc: 0.9069 - val_loss: 0.7347 - val_acc: 0.9075\n",
      "Epoch 4/10\n",
      "160000/160000 [==============================] - 10s 60us/step - loss: 0.7347 - acc: 0.9079 - val_loss: 0.7335 - val_acc: 0.9079\n",
      "Epoch 5/10\n",
      "160000/160000 [==============================] - 10s 63us/step - loss: 0.7315 - acc: 0.9081 - val_loss: 0.7307 - val_acc: 0.9079\n",
      "Epoch 6/10\n",
      "160000/160000 [==============================] - 10s 63us/step - loss: 0.7296 - acc: 0.9085 - val_loss: 0.7382 - val_acc: 0.9055\n",
      "Epoch 7/10\n",
      "160000/160000 [==============================] - 9s 57us/step - loss: 0.7282 - acc: 0.9081 - val_loss: 0.7298 - val_acc: 0.9069\n",
      "Epoch 8/10\n",
      "160000/160000 [==============================] - 8s 51us/step - loss: 0.7267 - acc: 0.9088 - val_loss: 0.7309 - val_acc: 0.9071\n",
      "Epoch 9/10\n",
      "160000/160000 [==============================] - 10s 62us/step - loss: 0.7255 - acc: 0.9091 - val_loss: 0.7285 - val_acc: 0.9061\n",
      "Epoch 10/10\n",
      "160000/160000 [==============================] - 9s 57us/step - loss: 0.7248 - acc: 0.9092 - val_loss: 0.7229 - val_acc: 0.9080\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()                                                                                                          \n",
    "model.add(keras.layers.Dense(1024, activation = 'relu', input_shape = (200,), kernel_regularizer=keras.regularizers.l1(0.001)))                                                            \n",
    "model.add(keras.layers.Dense(512, activation = 'relu', kernel_regularizer=keras.regularizers.l1(0.001)))                                                                                     \n",
    "model.add(keras.layers.Dense(256, activation = 'relu', kernel_regularizer=keras.regularizers.l1(0.001))) \n",
    "model.add(keras.layers.Dense(128, activation = 'relu',kernel_regularizer=keras.regularizers.l1(0.001)))                                                                             \n",
    "model.add(keras.layers.Dense(64, activation = 'relu',kernel_regularizer=keras.regularizers.l1(0.001))) \n",
    "model.add(keras.layers.Dense(32, activation = 'relu',kernel_regularizer=keras.regularizers.l1(0.001)))                                                                          \n",
    "model.add(keras.layers.Dense(16, activation = 'relu', kernel_regularizer=keras.regularizers.l1(0.001)))                                                                                    \n",
    "model.add(keras.layers.Dense(1, activation = 'sigmoid'))                                                                                   \n",
    "model.compile(optimizer='rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy']) \n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_val, y_val), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
