{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path = './train.csv'):\n",
    "    data = pd.read_csv(path)\n",
    "    X = data.drop(['target', 'ID_code'], 1)\n",
    "    y = data.target\n",
    "    prop = (y == 0).sum().astype(float)/(y == 1).sum()\n",
    "    X_train, X_val, y_train, y_val = skl.model_selection.train_test_split(X, y, \n",
    "                                            test_size=0.1, random_state=1, shuffle=False)\n",
    "    return X_train, X_val, y_train, y_val, prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_transform(X_train, transformer):\n",
    "    Transformer = transformer\n",
    "    Transformer.fit(X_train)\n",
    "    X_train = Transformer.transform(X_train)\n",
    "    return X_train, Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_prediction(model, X_train, y_train, X_val, y_val, scaler):\n",
    "    X_test = np.array(scaler.transform(X_val))\n",
    "    fpr, tpr, thresholds = skl.metrics.roc_curve(y_train, model.predict(X_train))\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    pred = model.predict(X_test)\n",
    "    pred = (pred > optimal_threshold).astype(int)\n",
    "    print(skl.metrics.roc_auc_score(y_val, pred))\n",
    "    return skl.metrics.roc_auc_score(y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(estimator, X, y):\n",
    "    prediction = estimator.predict(X)\n",
    "    fpr, tpr, thresholds = skl.metrics.roc_curve(y, prediction)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    pred = (prediction > optimal_threshold).astype(int)\n",
    "    return skl.metrics.roc_auc_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(transformer, params, grid, n_iter=100, cv=3):\n",
    "    X_train, X_val, y_train, y_val, prop = prepare_data()\n",
    "    X_train, Transformer = fit_and_transform(X_train, transformer)\n",
    "    booster = xgb.XGBRegressor(**params, scale_pos_weight=1/prop)\n",
    "    rs = skl.model_selection.RandomizedSearchCV(cv=cv, n_jobs=1, verbose=100, scoring=auc,\n",
    "                                       estimator=booster, param_distributions=grid, n_iter=n_iter, random_state=1)\n",
    "    rs.fit(X_train, np.array(y_train))\n",
    "    result = validate_prediction(rs.best_estimator_, X_train, y_train, X_val, y_val, transformer)\n",
    "    return result, rs.best_params_, rs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = [skl.preprocessing.MaxAbsScaler(), skl.preprocessing.MinMaxScaler(), skl.preprocessing.Normalizer(),\n",
    "               skl.preprocessing.StandardScaler(), skl.preprocessing.RobustScaler(), \n",
    "                skl.preprocessing.QuantileTransformer(), skl.preprocessing.FunctionTransformer()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective':'binary:logistic', 'eval_metric': 'auc', 'n_jobs': 12, 'tree_method': 'hist', \n",
    "          'verbosity':1, 'booster': 'gbtree', 'n_estimators': 100, \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'alpha': np.exp(np.linspace(-10, 10, 10)),\n",
    "        'lambda': np.exp(np.linspace(-10, 10, 10)),\n",
    "        'colsample_bytree': [0.2, 0.5, 0.8, 1],\n",
    "        'colsample_bylevel': [0.2, 0.5, 0.8, 1],\n",
    "        'colsample_bynode': [0.2, 0.5, 0.8, 1],\n",
    "        'subsample': [0.2, 0.5, 0.8, 1],\n",
    "        'max_delta_step': [0, 1, 10],\n",
    "        'min_child_weight': [1, 5, 10, 100],\n",
    "        'max_depth': [3, 5, 16, 50, 100], \n",
    "        'gamma': np.exp(np.linspace(-10, 10, 10)),\n",
    "        'eta': np.exp(np.linspace(-5, 0, 10))\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxAbsScaler(copy=True)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718 \n",
      "[CV]  subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718, score=0.676, total=   2.2s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[CV] subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718 \n",
      "[CV]  subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718, score=0.689, total=   2.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      "0.7094404126285768\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718 \n",
      "[CV]  subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718, score=0.676, total=   1.9s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[CV] subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718 \n",
      "[CV]  subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718, score=0.689, total=   2.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "0.7094404126285768\n",
      "Normalizer(copy=True, norm='l2')\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718 \n",
      "[CV]  subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718, score=0.662, total=   2.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[CV] subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718 \n",
      "[CV]  subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718, score=0.674, total=   2.1s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "0.7009719743750487\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718 \n",
      "[CV]  subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718, score=0.676, total=   1.9s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[CV] subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718 \n",
      "[CV]  subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718, score=0.689, total=   2.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "0.7094404126285768\n",
      "RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718 \n",
      "[CV]  subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718, score=0.676, total=   1.9s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[CV] subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718 \n",
      "[CV]  subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718, score=0.689, total=   2.1s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s finished\n",
      "0.7094404126285768\n",
      "QuantileTransformer(copy=True, ignore_implicit_zeros=False, n_quantiles=1000,\n",
      "                    output_distribution='uniform', random_state=None,\n",
      "                    subsample=100000)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718 \n",
      "[CV]  subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718, score=0.676, total=   2.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[CV] subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718, score=0.683, total=   1.9s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "0.699454965514081\n",
      "FunctionTransformer(accept_sparse=False, check_inverse=True, func=None,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grzegorz/anaconda3/envs/DeepLearning/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/home/grzegorz/anaconda3/envs/DeepLearning/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718 \n",
      "[CV]  subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718, score=0.676, total=   2.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[CV] subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718 \n",
      "[CV]  subsample=0.2, min_child_weight=100, max_depth=5, max_delta_step=0, lambda=258.67063051550025, gamma=0.0004189421234483841, eta=0.06217652402211632, colsample_bytree=1, colsample_bynode=0.8, colsample_bylevel=0.2, alpha=22026.465794806718, score=0.689, total=   2.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grzegorz/anaconda3/envs/DeepLearning/lib/python3.6/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7094404126285768\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "models = []\n",
    "parameters = []\n",
    "for transformer in transformers:\n",
    "    print(transformer)\n",
    "    res, bp, bm = fit_model(transformer, params, grid, n_iter=1, cv=2)\n",
    "    results.append(res)\n",
    "    models.append(bm)\n",
    "    parameters.append(bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.709440\n",
       "1    0.709440\n",
       "2    0.700972\n",
       "3    0.709440\n",
       "4    0.709440\n",
       "5    0.699455\n",
       "6    0.709440\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsample</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_delta_step</th>\n",
       "      <th>lambda</th>\n",
       "      <th>gamma</th>\n",
       "      <th>eta</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>colsample_bynode</th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>alpha</th>\n",
       "      <th>results</th>\n",
       "      <th>transformer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>258.67063051550025</td>\n",
       "      <td>0.0004189421234483841</td>\n",
       "      <td>0.06217652402211632</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22026.465794806718</td>\n",
       "      <td>0.7094404126285768</td>\n",
       "      <td>MaxAbsScaler(copy=True)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>258.67063051550025</td>\n",
       "      <td>0.0004189421234483841</td>\n",
       "      <td>0.06217652402211632</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22026.465794806718</td>\n",
       "      <td>0.7094404126285768</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>258.67063051550025</td>\n",
       "      <td>0.0004189421234483841</td>\n",
       "      <td>0.06217652402211632</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22026.465794806718</td>\n",
       "      <td>0.7009719743750487</td>\n",
       "      <td>Normalizer(copy=True, norm='l2')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>258.67063051550025</td>\n",
       "      <td>0.0004189421234483841</td>\n",
       "      <td>0.06217652402211632</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22026.465794806718</td>\n",
       "      <td>0.7094404126285768</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>258.67063051550025</td>\n",
       "      <td>0.0004189421234483841</td>\n",
       "      <td>0.06217652402211632</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22026.465794806718</td>\n",
       "      <td>0.7094404126285768</td>\n",
       "      <td>RobustScaler(copy=True, quantile_range=(25.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>258.67063051550025</td>\n",
       "      <td>0.0004189421234483841</td>\n",
       "      <td>0.06217652402211632</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22026.465794806718</td>\n",
       "      <td>0.699454965514081</td>\n",
       "      <td>QuantileTransformer(copy=True, ignore_implicit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>258.67063051550025</td>\n",
       "      <td>0.0004189421234483841</td>\n",
       "      <td>0.06217652402211632</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22026.465794806718</td>\n",
       "      <td>0.7094404126285768</td>\n",
       "      <td>FunctionTransformer(accept_sparse=False, check...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subsample min_child_weight max_depth max_delta_step              lambda  \\\n",
       "0       0.2              100         5              0  258.67063051550025   \n",
       "1       0.2              100         5              0  258.67063051550025   \n",
       "2       0.2              100         5              0  258.67063051550025   \n",
       "3       0.2              100         5              0  258.67063051550025   \n",
       "4       0.2              100         5              0  258.67063051550025   \n",
       "5       0.2              100         5              0  258.67063051550025   \n",
       "6       0.2              100         5              0  258.67063051550025   \n",
       "\n",
       "                   gamma                  eta colsample_bytree  \\\n",
       "0  0.0004189421234483841  0.06217652402211632                1   \n",
       "1  0.0004189421234483841  0.06217652402211632                1   \n",
       "2  0.0004189421234483841  0.06217652402211632                1   \n",
       "3  0.0004189421234483841  0.06217652402211632                1   \n",
       "4  0.0004189421234483841  0.06217652402211632                1   \n",
       "5  0.0004189421234483841  0.06217652402211632                1   \n",
       "6  0.0004189421234483841  0.06217652402211632                1   \n",
       "\n",
       "  colsample_bynode colsample_bylevel               alpha             results  \\\n",
       "0              0.8               0.2  22026.465794806718  0.7094404126285768   \n",
       "1              0.8               0.2  22026.465794806718  0.7094404126285768   \n",
       "2              0.8               0.2  22026.465794806718  0.7009719743750487   \n",
       "3              0.8               0.2  22026.465794806718  0.7094404126285768   \n",
       "4              0.8               0.2  22026.465794806718  0.7094404126285768   \n",
       "5              0.8               0.2  22026.465794806718   0.699454965514081   \n",
       "6              0.8               0.2  22026.465794806718  0.7094404126285768   \n",
       "\n",
       "                                         transformer  \n",
       "0                            MaxAbsScaler(copy=True)  \n",
       "1      MinMaxScaler(copy=True, feature_range=(0, 1))  \n",
       "2                   Normalizer(copy=True, norm='l2')  \n",
       "3  StandardScaler(copy=True, with_mean=True, with...  \n",
       "4  RobustScaler(copy=True, quantile_range=(25.0, ...  \n",
       "5  QuantileTransformer(copy=True, ignore_implicit...  \n",
       "6  FunctionTransformer(accept_sparse=False, check...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.DataFrame(parameters)\n",
    "tmp['results'] = results\n",
    "tmp['transformer'] = transformers\n",
    "tmp = tmp.astype(str)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
